---
layout: post
title: QHub on Google Cloud deployment notes
---

When you're working with large datasets, access to good tools and computing infrastructure obviously really matters. Back in 2019, we started an internal project to deploy [JupyterHub](https://jupyter.org/hub) and [Dask](https://dask.org/) on Google Cloud, following the example set by the [Pangeo project](https://pangeo.io/). Having access to Jupyter in the cloud, with Dask clusters on demand, has proved to be very valuable for our mosquito genomic data engineering and analysis team at MalariaGEN, and we've come to rely on it for much of our work. However, our devops engineer Krzysztof Kluczynski ([@sledops](https://github.com/slejdops)), who set up the system for us, got pulled onto other projects, and didn't have much time to keep up with maintaining the system. Recently, I was pointed to a new project called [QHub](https://docs.qhub.dev/), which provides infrastructure-as-code for deploying JupyterHub and Dask on your cloud provider of choice. This looked like a very attractive proposition for upgrading our system and reducing the maintenance burden, as many of the complexities of integrating the various technologies and deploying them on cloud infrastructure are potentially taken care of. It is a relatively new project, however, so I thought I'd try it out to learn more. 

With QHub, you edit a single YAML configuration file which specifies everthing about your infrastructure, including which cloud provider you want to use, how users will authenticate, what types of VM they can use, what conda environments are available, etc. Then the `qhub deploy` command takes care of creating or modifying all the infrastructure and services needed. Behind the scenes, `qhub deploy` uses [Terraform](https://www.terraform.io/), which then interacts with your chosen cloud provider via [Kubernetes](https://kubernetes.io/). I'm no devops engineer, and I know next-to-nothing abut Kubernetes or Terraform; but the QHub project is aiming to make deployment simple enough that data science teams can manage it themselves, so putting it in the hands of a mosquito biologist is probably not a bad test!

TL;DR after about a week of experimentation I've got to what feels like a pretty good place, with a fully functioning JupyterHub deployment on Google Cloud, with autoscaling Dask clusters on demand. I've also figured out processes for doing much of the maintenance I know I'll need, including adding or updating the conda environments that are available to users, and making enhancements to the Docker image which runs the main Jupyter Lab service that users interact with. There were a few bumps along the way, however, and I had to come up with a few hacks and workarounds, so I thought it might be worth sharing the experience.

N.B., all of the below was done using QHub version 0.3.11. The project looks like it's moving pretty fast, so much if not all of this will probably get out of date very soon. Check in with the [QHub docs](https://docs.qhub.dev/) for latest information.

## Vanilla deployment

Here I'm deploying on Google Cloud. I've previously created a Google
Cloud account and set up billing. I also have conda installed on my
local system. Here's a summary of everything I did to get a vanilla deployment up and running, which all went smoothly. Most of this is just following the Getting Started docs.



## Configuration and lessons learned

After I had the vanilla deployment in place, I wanted to customise the
configuration to add some additional capabilities that I and my team
will need.


### Manual deployment

@@TODO github actions didn't work, so had to manually deploy using
command line. In the end glad I did, lots of things went wrong, would
have been very messy if all happening via CI/CD. Advise to start
working on a new deployment in a new branch (not main), and manually
deploy. When initial deployment is working, then can consider CI/CD
for small/incremental changes.


### Adding node pools and optimising resource requests

@@TODO making good use of k8s


### Don't change the namespace

@@TODO


### Manual destruction

@@TODO sometimes things go badly wrong. qhub destroy fails. manual
destruction necessary.


### Design for multiple deployments

@@TODO plan to have multiple deployments. Reason is that can provision
a stable environment for team. Then start working on a new deployment
if need to make any major changes, run alongside. Then ask team to
migrate when new deployment is stable, then shut down the old.


### Adding conda environments

@@TODO sometimes solving hangs. workaround is to pre-solve locally,
then export and include fully pinned environment in qhub config.


### Final working configuration

@@TODO here's the config file as a I currently have it, in case it's
useful.


## Future requirements and open questions


### Adding system packages to the user (jupyterlab) image

@@TODO


### Managing persistent storage

@@TODO slightly concerned that no quotas, all one pool. Either set
quotas or have separate disks. Also what if need to expand storage as
more users come on board.


### Managing conda environments

@@TODO

* previous environments not deleted. maybe feature or bug

* solving fails or takes ages

* ability to put environments in separate files, rather than inline
  within qhub-config.yaml


### Dask pinning

@@TODO currently pinning dask and distributed is required according to
docs. But some way behind. Totally understand the need to pin, this is
a complicated set of technologies. But will need to be able to manage
this and move forward. See also discussion.
