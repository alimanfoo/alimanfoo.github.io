---
layout: post
title: QHub on Google Cloud deployment notes
---

I've spent the last few days trying out
[QHub](https://docs.qhub.dev/), which is an open source project that
provides infrastructure as code for deploying an interactive computing
environment for data science teams, including Jupyter and Dask. This
blog post has some deployment notes, lessons learned and open
questions. TL;DR QHub is very promising, but it is still a new
project, expect some turbulence.

With QHub, you edit a YAML configuration file which specifies various
things, like which cloud provider you want to use, what conda
environments you want to provide, what domain name you will use to
deploy, how users will authenticate, what types of VM they can use,
etc. Then the `qhub deploy` command takes care of setting up and
deploying all the infrastructure. Behind the scenes, `qhub deploy`
uses [Terraform](https://www.terraform.io/), which then interacts with
your chosen cloud provider.

Here I'm deploying on Google Cloud. I've previously created a Google
Cloud account and set up billing. I also have conda installed on my
local system. Everything here was done using qhub version 0.3.11, I
expect things may change quite a bit over the next few versions, so
check with the latest docs.


## Vanilla deployment

I first tried to get a completely vanilla deployment up and running,
following the getting started sections in the [QHub
docs](https://docs.qhub.dev/en/stable/index.html). This all went
smoothly and I had a working deployment, including auto-scaling Dask
clusters, in less than a day. Here's a brief summary of what I had to
do.


## Configuration and lessons learned

After I had the vanilla deployment in place, I wanted to customise the
configuration to add some additional capabilities that I and my team
will need.


### Manual deployment

@@TODO github actions didn't work, so had to manually deploy using
command line. In the end glad I did, lots of things went wrong, would
have been very messy if all happening via CI/CD. Advise to start
working on a new deployment in a new branch (not main), and manually
deploy. When initial deployment is working, then can consider CI/CD
for small/incremental changes.


### Adding node pools and optimising resource requests

@@TODO making good use of k8s


### Don't change the namespace

@@TODO


### Manual destruction

@@TODO sometimes things go badly wrong. qhub destroy fails. manual
destruction necessary.


### Design for multiple deployments

@@TODO plan to have multiple deployments. Reason is that can provision
a stable environment for team. Then start working on a new deployment
if need to make any major changes, run alongside. Then ask team to
migrate when new deployment is stable, then shut down the old.


### Adding conda environments

@@TODO sometimes solving hangs. workaround is to pre-solve locally,
then export and include fully pinned environment in qhub config.


### Final working configuration

@@TODO here's the config file as a I currently have it, in case it's
useful.


## Future requirements and open questions


### Adding system packages to the user (jupyterlab) image

@@TODO


### Managing persistent storage

@@TODO slightly concerned that no quotas, all one pool. Either set
quotas or have separate disks. Also what if need to expand storage as
more users come on board.


### Managing conda environments

@@TODO

* previous environments not deleted. maybe feature or bug

* solving fails or takes ages

* ability to put environments in separate files, rather than inline
  within qhub-config.yaml


### Dask pinning

@@TODO currently pinning dask and distributed is required according to
docs. But some way behind. Totally understand the need to pin, this is
a complicated set of technologies. But will need to be able to manage
this and move forward. See also discussion.
